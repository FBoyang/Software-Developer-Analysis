{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from urllib.request import Request, urlopen\n",
    "reload(sys)\n",
    "\n",
    "\n",
    "\n",
    "driver = webdriver.Chrome() #(executable_path=r\"C:\\Users\\fbyan\\Miniconda3\\Scripts\\chromedriver.exe\")\n",
    "\n",
    "#url2 = 'https://www.linkedin.com/jobs/search/?keywords=Software%20Developer&location=Worldwide&locationId=OTHERS.worldwide'\n",
    "url ='https://www.glassdoor.com/Job/software-developer-jobs-SRCH_KO0,18.htm'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "infor = 0\n",
    "\n",
    "#create a new file in the current directory called job.txt\n",
    "f = open('job.txt', 'w')\n",
    "#find content in the first page\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'html.parser') #lxml\n",
    "for text in soup.find_all('div',{\"class\":\"jobDescriptionContent desc\"}):\n",
    "    infor += 1\n",
    "    f.write(text.text)\n",
    "\n",
    "#deal with the pop-up window in the second page\n",
    "driver.find_element_by_link_text(str(2)).click()\n",
    "time.sleep(5)\n",
    "driver.find_element_by_xpath(\"//button[@type='button' and @class='mfp-close']\").click()\n",
    "time.sleep(5)\n",
    "html = driver.page_source\n",
    "soup = BeautifulSoup(html,'html.parser') #lxml\n",
    "for text in soup.find_all('div',{\"class\":\"jobDescriptionContent desc\"}):\n",
    "            infor += 1\n",
    "            f.write(text.text)\n",
    "\n",
    "def execute_times(times):\n",
    "    global infor, f\n",
    "    for i in range(3, times + 1):\n",
    "        driver.find_element_by_link_text(str(i)).click()\n",
    "        #driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(5)\n",
    "        \n",
    "        #record the number of job discreption into infor (further we will need to record more metadata, so later we will apply numpy\n",
    "        #but first check wether the number is correct)\n",
    "        html = driver.page_source\n",
    "        soup = BeautifulSoup(html,'html.parser') #lxml\n",
    "        for text in soup.find_all('div',{\"class\":\"jobDescriptionContent desc\"}):\n",
    "            infor += 1\n",
    "            f.write(text.text)\n",
    "            \n",
    "execute_times(5)\n",
    "\n",
    "f.write(\"data size is: \" + str(infor))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
